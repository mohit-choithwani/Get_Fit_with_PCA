# -*- coding: utf-8 -*-
"""Fitness_app_complete_(4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cd_Wi-6M8fkPygUsZsocz_8WaeaMi5zO

# Fitness App

outline:-
1. Importing libraries
2. Load Reference excel, reference image and complete data
3. Helper functions

  3.a. Kabsch_umeyama Algorithm

  3.b Function to return x and y cordinates from a vector

  3.c Function to plot x and y cordinates on the Reference Image

  3.d Function that returns four center cordinates

  3.e function that returns the transformed (Aligned) vector

  3.f Function to generate Random samples from parameters

  3.g Function to plot cordinates on Image

  3.h Function to Generate Random samples from Params

4. Plot the reference Image with x and y reference cordinates
5. Performing all the steps on full data of single video
6. Calculate the mean of normalized
7. Calculating the Mean-free data
8. Use mean free data to generate samples
"""

pip install mediapipe

import numpy as np
import pandas as pd
import matplotlib
from matplotlib import pyplot as plt
import scipy
from scipy import spatial
from numpy import random, linalg
from scipy.stats import shapiro
from random import seed
from random import randint
from numpy.random import seed
from matplotlib import image
import pickle
from numpy.linalg import norm

from google.colab import drive
drive.mount('/content/drive')

"""#Load all the files and reference Image"""

img = image.imread('/content/drive/MyDrive/AI_fitness_app/reference1_hands_midway.png')
reference_frame = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/reference1_hands_midway.xlsx')
full_data = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/all_frontal.xlsx')

v = pickle.load(open("/content/drive/MyDrive/AI_fitness_app/v.pickle", "rb"))
u = pickle.load(open("/content/drive/MyDrive/AI_fitness_app/u.pickle", "rb"))
B = pickle.load(open("/content/drive/MyDrive/AI_fitness_app/B.pickle", "rb"))
normalized_data_list = pickle.load(open("/content/drive/MyDrive/AI_fitness_app/normalized_data_list.pickle", "rb"))

B.shape

"""#**Helper Functions**

#Creat a function that finds optimal rotation and translation between two points to align on each other
"""

def kabsch_umeyama(A, B):
    assert A.shape == B.shape
    n, m = A.shape

    EA = np.mean(A, axis=0)
    EB = np.mean(B, axis=0)
    VarA = np.mean(np.linalg.norm(A - EA, axis=1) ** 2)

    H = ((A - EA).T @ (B - EB)) / n
    U, D, VT = np.linalg.svd(H)
    d = np.sign(np.linalg.det(U) * np.linalg.det(VT))
    S = np.diag([1] * (m - 1) + [d])

    R = U @ S @ VT
    c = VarA / np.trace(np.diag(D) @ S)
    t = EA - c * R @ EB

    return R, c, t

"""#function to return 2 list of x-cordinates and y-cordinates from a vector"""

#function to return 2 list of x-cordinates and y-cordinates from a vector
def return_x_and_y_cordinates(A):
  shape_of_vector = A.shape
  #print(len(A.shape))
  if(len(shape_of_vector) == 1):
    n = len(shape_of_vector)
    #print(A.shape)
  else:
   n, _ = A.shape

  x_cordinates = []
  y_cordinates = []

  for i in range(n):
    x_cordinates.append(A[i][0])
    y_cordinates.append(A[i][1])

  print('x--->{}, y--->{}'.format(x_cordinates, y_cordinates))

  return (x_cordinates, y_cordinates)

"""#Function to plot the cordinates on the image"""

def plot_cordinates_on_img(img, x_cordinates, y_cordinates):
  plt.imshow(img)
  plt.scatter(x=x_cordinates, y=y_cordinates, c='r', s=5)
  plt.show()

"""#Function that returns four center cordinates"""

#function to return 2 list of x-cordinates and y-cordinates for only four cordinates (2, 3, 14, 15)
def return_center_x_and_y_cordinates(A):
  shape_of_vector = A.shape
  #print(len(A.shape))
  if(len(shape_of_vector) == 1):
    n = len(shape_of_vector)
    #print(A.shape)
  else:
   n, _ = A.shape

  x_cordinates = []
  y_cordinates = []

  for i in range(n):
    if(i in [1, 2, 13, 14]):
      x_cordinates.append(A[i][0])
      y_cordinates.append(A[i][1])

  print('Center cordinates x--->{}, y--->{}'.format(x_cordinates, y_cordinates))

  return (x_cordinates, y_cordinates)

"""#Function that return numpy array of four cordinates"""

import numpy as np

def return_numpy_four_x_and_y_cordinates(A):
  shape_of_vector = A.shape
  #print(len(A.shape))
  if(len(shape_of_vector) == 1):
    n = len(shape_of_vector)
    #print(A.shape)
  else:
   n, _ = A.shape

  # x_cordinates = []
  # y_cordinates = []
  x_and_y_list = []

  for i in range(n):
    if(i in [1, 2, 13, 14]):
      # x_cordinates.append(A[i][0])
      # y_cordinates.append(A[i][1])
      x_and_y_list.append([A[i][0], A[i][1]])


  print('Numpy cordinates --->{}'.format(x_and_y_list))

  return np.array(x_and_y_list)

def get_transformed_vector(single_row_numpy):
  #Load the reference frame
  reference_frame = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/reference1_hands_midway.xlsx')

  #convert the frame into the numpy
  reference_frame_numpy = reference_frame.to_numpy()

  #Reshape the numpy into Nx2 vector
  reference_frame_numpy = reference_frame_numpy.reshape(23, 2)

  #print(reference_frame_numpy)

  #reference_x, reference_y = return_x_and_y_cordinates(reference_frame_numpy)
  #plt.scatter(reference_x, reference_y, color='g')
  #reference_center_x, reference_center_y = return_center_x_and_y_cordinates(reference_frame_numpy)

  #Reference frame - Stores the four center cordinates
  #This is used for alignment
  reference_frame_center_cordinates = return_numpy_four_x_and_y_cordinates(reference_frame_numpy)

  #store only the four center cordinates from the input
  single_row_center_cordinates = return_numpy_four_x_and_y_cordinates(single_row_numpy)

  #Apply the Kabsch function
  R, c, t = kabsch_umeyama(reference_frame_center_cordinates, single_row_center_cordinates)

  #trans_vec = Transformed vector
  trans_vec = np.array([t + c * R @ b for b in single_row_numpy])

  return trans_vec

"""#***"""

#Function to plot cordinates on the image
def plot_cordinates_on_image(transformed_vector):
  align_points_x, align_points_y = return_x_and_y_cordinates(transformed_vector)

  #Get the shape of the image
  width, height, _ = img.shape

  #Multipying the cordinates with width and height
  new_x = [x*height for x in align_points_x]
  new_y = [y*width for y in align_points_y]
  print(new_x, new_y)
  plot_cordinates_on_img(img, new_x, new_y)

#Function to plot cordinates on scatter plot
def plot_cordinates_on_scatter_plot(transformed_vector):
  align_points_x, align_points_y = return_x_and_y_cordinates(transformed_vector)

  plt.scatter(x=align_points_x, y=align_points_y, c='r', s=5)
  plt.show()

"""#plot the reference frame"""

width, height, _ = img.shape
reference_frame = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/reference1_hands_midway.xlsx')

#convert the frame into the numpy
reference_frame_numpy = reference_frame.to_numpy()

#Reshape the numpy into Nx2 vector
reference_frame_numpy = reference_frame_numpy.reshape(23, 2)

#print(reference_frame_numpy)

#plt.scatter(reference_x, reference_y, color='g')
reference_center_x, reference_center_y = return_center_x_and_y_cordinates(reference_frame_numpy)

#Reference frame
reference_frame_center_cordinates = return_numpy_four_x_and_y_cordinates(reference_frame_numpy)

#Multiplying the reference center cordinates with width and height
new_center_x = [x*height for x in reference_center_x]
new_center_y = [y*width for y in reference_center_y]

#plot only fout center cordinates
plot_cordinates_on_img(img, new_center_x, new_center_y)

#plot all the cordinates
plot_cordinates_on_image(reference_frame_numpy)

"""#Performing all the steps on full data of single video
No need to run this cell (we have the pickle file for normalized landmarks)
"""

rows, _ = full_data.shape

normalized_data_list = []

for i in range(rows-50):

  #Get every 20th frame
  #if (i % 20 == 0):
    print('Frame number is {}'.format(i))

    single_row = full_data.iloc[i]

    single_row_numpy = single_row.to_numpy()

    single_row_numpy = single_row_numpy.reshape(23, 2)

    # #Taking only the four cordinates into the consideration
    # single_row_center_cordinates = return_numpy_four_x_and_y_cordinates(single_row_numpy)

    # # #plot the first cordinates
    # # frame_x, frame_y = return_x_and_y_cordinates(single_row_numpy)

    # #Apply the Kabsch function
    # R, c, t = kabsch_umeyama(reference_frame_center_cordinates, single_row_center_cordinates)

    # #print('Rotation-->{}, translation-->{}, scaling-->{}'.format(R,t,c))
    # B = np.array([t + c * R @ b for b in single_row_numpy])
    # #print('Aligned Vector--->{}'.format(B))

    #visulize the each cordinate after transformation
    #align_points_x, align_points_y = return_x_and_y_cordinates(B)

    #Call the function that returns the transformed (Aligned) vector
    transformed_vector = get_transformed_vector(single_row_numpy)

    #Function that plot cordinates of the transformed vector on the image
    plot_cordinates_on_image(transformed_vector)

    # #Get the shape of the image
    # width, height, _ = img.shape

    # #Multipying the cordinates with width and height
    # new_x = [x*height for x in align_points_x]
    # new_y = [y*width for y in align_points_y]

    # plot_cordinates_on_img(img, new_x, new_y)

    normalized_data_list.append(transformed_vector.flatten())

print(len(normalized_data_list))

#Store the normalized data into some new variable
test_correct_data = normalized_data_list

test_mean_correct, test_correct_meanfree_data = calculate_mean_and_mean_free_data(normalized_data_list)

# print(test_correct_data[0])
# print(test_correct_meanfree_data[0])

"""#Funct to Generate Random samples from Params

### Function to calculate svd
"""

#Function that perform SVD and returns u, s, v
def perform_SVD(data):
  #print('Shape of data--->',data.shape)
  mean_free_data_transpose = data.T
  #print('Shape of transpose --->',mean_free_data_transpose.shape)

  u, s, v = np.linalg.svd(mean_free_data_transpose, full_matrices=True)

  print('Shape of u',u.shape)
  print('Shape of s',s.shape)
  print('shape of v',v.shape)

  rows, columns = data.shape

  #New matrix B is a digonal matrix which has u no. of rows and v no. of columns
  #and diagonal elements are same as S
  B = np.zeros(data.shape)
  for i in range(rows) :
      for j in range(columns) :
          if i == j : B[i,j] = s[j]

  return (u, B, v)

"""###Function to generate samples from u, S, parameters and data"""

def calculate_sample(u, B, paramameter, data):
  rows, columns = data.T.shape
  DpowHalf = B / np.sqrt(rows)
  print('shape of dpowHalf--->',DpowHalf.shape)

  sample_wo_param = u@DpowHalf.T
  print('sample_wo_param shape',sample_wo_param.shape)
  #print(sample_wo_param)
  sample = sample_wo_param@paramameter
  print('sample shape--->',sample.shape)
  return sample

"""#Function to calculate mean of the data and return mean and meanfree data"""

def calculate_mean_and_mean_free_data(normalized_data):
  #Converting list into pandas data frame
  normalized_data_frame = pd.DataFrame(normalized_data)
  #normalized_data_frame.head()
  print('normalized_data_frame--->{}'.format(normalized_data_frame.shape))

  #calculating mean of all data
  mean_all_frames = normalized_data_frame.mean(axis=0)
  mean_all_frames_numpy = mean_all_frames.to_numpy()
  #print('mean_all_frames_numpy--->{}'.format(mean_all_frames_numpy.shape))
  mean_all_frames_numpy = mean_all_frames_numpy.reshape(23, 2)
  print('Mean --->{}'.format(mean_all_frames_numpy.shape))

  #plot the mean on referencee image
  plot_cordinates_on_image(mean_all_frames_numpy)

  #Calculating the mean-free data
  mean = mean_all_frames_numpy.flatten()
  mean_free_data = normalized_data_frame - mean
  print('mean_free_data shape--->{}'.format(mean_free_data.shape))

  return (mean, mean_free_data)

"""#Final Code"""

# img = image.imread('/content/reference1_hands_midway.png')
# reference_frame = pd.read_excel('/content/reference1_hands_midway.xlsx')
# # full_data = pd.read_excel('/content/all_frontal.xlsx')
# incorrect_video_1 = pd.read_excel('/content/incorrect_video_1.xlsx')
# incorrect_video_2 = pd.read_excel('/content/incorrect_video_2.xlsx')

# incorrect_frame_1 = pd.read_excel('/content/mohit1.xlsx')
# incorrect_frame_2 = pd.read_excel('/content/mohit2.xlsx')
# incorrect_frame_3 = pd.read_excel('/content/mohit3.xlsx')
# incorrect_frame_4 = pd.read_excel('/content/mohit4.xlsx')

incorrect_video_1 = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/incorrect_video_1.xlsx')
incorrect_video_2 = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/incorrect_video_2.xlsx')

# print(incorrect_video_1.shape)
incorrect_video_1 = incorrect_video_1.dropna()
incorrect_video_2 = incorrect_video_2.dropna()

incorrect_video_1.head()

"""# Rigid alignment of incorrect sample video

"""

in_rows, _ = incorrect_video_1.shape

in_normalized_data_list = []

for i in range(in_rows):

  # #Get every 20th frame
  # if (i % 10 == 0):
    print('Frame number is {}'.format(i))

    single_row = incorrect_video_1.iloc[i]

    single_row_numpy = single_row.to_numpy()

    single_row_numpy = single_row_numpy.reshape(23, 2)

    transformed_vector = get_transformed_vector(single_row_numpy)

    #Function that plot cordinates of the transformed vector on the image
    plot_cordinates_on_image(transformed_vector)

    in_normalized_data_list.append(transformed_vector.flatten())

print(len(in_normalized_data_list))

#Rigid alignment of incorrect video 2 and store its result into in_normalized_data_list_1 list
in_rows, _ = incorrect_video_2.shape

in_normalized_data_list_1 = []

for i in range(in_rows):

  # #Get every 20th frame
  # if (i % 10 == 0):
    print('Frame number is {}'.format(i))

    single_row = incorrect_video_2.iloc[i]

    single_row_numpy = single_row.to_numpy()

    single_row_numpy = single_row_numpy.reshape(23, 2)

    transformed_vector = get_transformed_vector(single_row_numpy)

    #Function that plot cordinates of the transformed vector on the image
    plot_cordinates_on_image(transformed_vector)

    in_normalized_data_list_1.append(transformed_vector.flatten())

print(len(in_normalized_data_list_1))

"""#Rigid alignment of Incorrect Frame (individual Images)
No need to run this cell
"""

incorrect_frame_numpy = incorrect_frame_1.to_numpy()

incorrect_frame_numpy = incorrect_frame_numpy.reshape(23, 2)

incorrect_transformed_vector_1 = get_transformed_vector(incorrect_frame_numpy)

#Function that plot cordinates of the transformed vector on the image
plot_cordinates_on_image(incorrect_transformed_vector_1)

incorrect_frame_numpy = incorrect_frame_2.to_numpy()
incorrect_frame_numpy = incorrect_frame_numpy - mean
incorrect_frame_numpy = incorrect_frame_numpy.reshape(23, 2)

incorrect_transformed_vector_2 = get_transformed_vector(incorrect_frame_numpy)

incorrect_transformed_vector_2 = incorrect_transformed_vector_2.flatten() - mean

incorrect_transformed_vector_2 = incorrect_transformed_vector_2.reshape(23, 2)
#Function that plot cordinates of the transformed vector on the image
plot_cordinates_on_image(incorrect_transformed_vector_2)

incorrect_frame_numpy = incorrect_frame_3.to_numpy()

incorrect_frame_numpy = incorrect_frame_numpy.reshape(23, 2)

incorrect_transformed_vector_3 = get_transformed_vector(incorrect_frame_numpy)

incorrect_transformed_vector_3 = incorrect_transformed_vector_3.flatten() - mean

incorrect_transformed_vector_3 = incorrect_transformed_vector_3.reshape(23, 2)
#Function that plot cordinates of the transformed vector on the image
plot_cordinates_on_image(incorrect_transformed_vector_3)

incorrect_frame_numpy = incorrect_frame_4.to_numpy()
incorrect_frame_numpy = incorrect_frame_numpy - mean
incorrect_frame_numpy = incorrect_frame_numpy.reshape(23, 2)

incorrect_transformed_vector_4 = get_transformed_vector(incorrect_frame_numpy)

#Function that plot cordinates of the transformed vector on the image
plot_cordinates_on_image(incorrect_transformed_vector_4)

"""# Perform Rigid alignment on full data
No need to run this cell, values of Normalized_list, U, V and B are stored in pickle file
"""

rows, _ = full_data.shape

#store the data in the normalized data list
normalized_data_list = []

for i in range(rows-20):

  #Get every 20th frame
  # if (i % 10 == 0):
    print('Frame number is {}'.format(i))

    single_row = full_data.iloc[i]

    single_row_numpy = single_row.to_numpy()

    single_row_numpy = single_row_numpy.reshape(23, 2)

    transformed_vector = get_transformed_vector(single_row_numpy)

    #Function that plot cordinates of the transformed vector on the image
    plot_cordinates_on_image(transformed_vector)

    normalized_data_list.append(transformed_vector.flatten())

print(len(normalized_data_list))

print(len(normalized_data_list))

"""#***"""

#calculate mean and mean-free-data

mean, mean_free_data = calculate_mean_and_mean_free_data(normalized_data_list)

#using mean free data to generate samples

#calculating svd on mean free data
u, B, v = perform_SVD(mean_free_data)

"""# Generating samples from random parameters"""

#setting the random parameters
rows, columns = mean_free_data.shape
rand_param = random.normal(size=(rows, 1))

rand_param_1 = np.zeros((rows, 1))
rand_param_1[0][0] = -1
#print('Random parameters are {}'.format(rand_param.shape))
#print(rand_param)

sample = calculate_sample(u, B, rand_param, mean_free_data)

#adding mean to the sample
resultant_vector = sample.flatten() + mean
resultant_vector = resultant_vector.reshape(23, 2)
print(resultant_vector)
#plot the sample
plot_cordinates_on_image(resultant_vector)



#setting the random parameters
rows, columns = mean_free_data.shape
rand_param = random.normal(size=(rows, 1))

# rand_param_1 = np.zeros((rows, 1))
# rand_param_1[0][0] = -1
#print('Random parameters are {}'.format(rand_param.shape))
#print(rand_param)

sample = calculate_sample(u, B, rand_param, mean_free_data)

#adding mean to the sample

resultant_vector = sample.flatten() + mean
resultant_vector = resultant_vector.reshape(23, 2)

#plot the sample
plot_cordinates_on_image(resultant_vector)

#setting the random parameters
rows, columns = mean_free_data.shape
rand_param = random.normal(size=(rows, 1))

# rand_param_1 = np.zeros((rows, 1))
# rand_param_1[0][0] = -1
#print('Random parameters are {}'.format(rand_param.shape))
#print(rand_param)

sample = calculate_sample(u, B, rand_param, mean_free_data)

#adding mean to the sample

resultant_vector = sample.flatten() + mean
resultant_vector = resultant_vector.reshape(23, 2)

#plot the sample
plot_cordinates_on_image(resultant_vector)

#setting the random parameters
rows, columns = mean_free_data.shape
rand_param = random.normal(size=(rows, 1))

# rand_param_1 = np.zeros((rows, 1))
# rand_param_1[0][0] = -1
#print('Random parameters are {}'.format(rand_param.shape))
#print(rand_param)

sample = calculate_sample(u, B, rand_param, mean_free_data)

#adding mean to the sample

resultant_vector = sample.flatten() + mean
resultant_vector = resultant_vector.reshape(23, 2)

#plot the sample
plot_cordinates_on_image(resultant_vector)

#setting the random parameters
rows, columns = mean_free_data.shape
rand_param = random.normal(size=(rows, 1))

# rand_param_1 = np.zeros((rows, 1))
# rand_param_1[0][0] = -1
#print('Random parameters are {}'.format(rand_param.shape))
#print(rand_param)

sample = calculate_sample(u, B, rand_param, mean_free_data)

#adding mean to the sample

resultant_vector = sample.flatten() + mean
resultant_vector = resultant_vector.reshape(23, 2)

#plot the sample
plot_cordinates_on_image(resultant_vector)



"""# Generating parameters from the Sample ***"""

def generate_parameters_from_sample(u, B, sample, data):
  # print('shape of u--->',u.shape)

  # print('shape of B--->',B.shape)

  # print('shape of sample--->',sample.shape)

  # print('shape of data--->',data.shape)

  rows, columns = data.shape

  DpowHalf = B / np.sqrt(rows)

  # print('shape of dpowHalf--->',DpowHalf.shape)
  # sample = sample.to_numpy()
  sample = sample.reshape((46, 1))
  # print('shape of sample--->',sample.shape)

  DpowHalf_inverse = np.linalg.pinv(DpowHalf)

  # print('shape of dpowHalf inverse--->',DpowHalf_inverse.shape)

  u_inverse = np.linalg.inv(u)

  # print('shape of U_inverse--->',u_inverse.shape)

  # u_and_dpow = DpowHalf@u

  # # print('shape of product',u_and_dpow.shape)
  # u_and_dpow_inverse = np.linalg.pinv(u_and_dpow)
  parameters = DpowHalf_inverse.T@u_inverse@sample

  # print('shape of product inverse',u_and_dpow.shape)
  # parameters = sample.T@u_and_dpow_inverse

  # print('shape of parameters--->',parameters.shape)

  #print('shape of u inverse --->',u_inverse.shape)

  #parameters = paramameters_temp@u_inverse

  return parameters

#incorrect_transformed_vector.shape

#Extract a random sample from the mean free data data
sample = mean_free_data.iloc[110]
sample = sample.to_numpy()

param = generate_parameters_from_sample(u, B, sample, mean_free_data)
#param = param.reshape((558,1))
print(param)

"""#Function to check whether parameters are gaussian or not"""

def check_for_gaussian(parameters):
  seed(1)
  # normality test
  stat, p = shapiro(parameters)
  print('Statistics={}, p={}'.format(stat, p))
  # interpret
  alpha = 0.05
  if p > alpha:
    print('Sample looks Gaussian (fail to reject H0)')
  else:
    print('Sample does not look Gaussian (reject H0)')

positive_param = param[param!=0]

check_for_gaussian(positive_param)

"""Test for correct frames"""

#Extract a random sample from the mean free data data
sample = mean_free_data.iloc[110]
sample = sample.to_numpy()

param = generate_parameters_from_sample(u, B, sample, mean_free_data)
print(param)

positive_param = param[param!=0]

check_for_gaussian(positive_param)

#Extract a random sample from the mean free data data
sample = mean_free_data.iloc[10]
sample = sample.to_numpy()

param = generate_parameters_from_sample(u, B, sample, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)

#Extract a random sample from the mean free data data
sample = mean_free_data.iloc[201]
sample = sample.to_numpy()

param = generate_parameters_from_sample(u, B, sample, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)



"""Test for incorrect frames"""

param = generate_parameters_from_sample(u, B, incorrect_transformed_vector_1, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)

param = generate_parameters_from_sample(u, B, incorrect_transformed_vector_2, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)

param = generate_parameters_from_sample(u, B, incorrect_transformed_vector_3, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)

param = generate_parameters_from_sample(u, B, incorrect_transformed_vector_4, mean_free_data)

positive_param = param[param!=0]

check_for_gaussian(positive_param)













"""#

# Test L2 norm of first 10 values of the parameters
"""

from numpy.linalg import norm

"""##Generate mean_free data from the correct video and find it's L2 norm"""

#lets generate mean_free data from the correct video
correct_video = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/mohit_frontal.xlsx')
col_mean = correct_video.mean(axis=0)

mean_free_correct_data = correct_video - col_mean
mean_free_correct_data.head()

#Extract a random sample from the  data
sample = test_correct_meanfree_data.iloc[28]
sample = sample.to_numpy()

param = generate_parameters_from_sample(u, B, incorrect_transformed_vector_2, mean_free_data)
#param = param.reshape((558,1))
#print(param)

first_10_param = param[:10]
print('First 10 parameters are--->',first_10_param)

#calculating the norm of first 10 parameters
norm_of_parameters = norm(first_10_param)
print('norm_of_parameters--->',norm_of_parameters)

#for loop to iterate over all the meanfree data and calculates its norm
# print(test_correct_meanfree_data.shape)
rows, columns = mean_free_correct_data.shape

for i in range(rows):
  sample = mean_free_correct_data.iloc[i]
  sample = sample.to_numpy()

  param = generate_parameters_from_sample(u, B, sample, mean_free_data)
  #param = param.reshape((558,1))
  #print(param)

  first_10_param = param[:10]
  # print('First 10 parameters are--->',first_10_param)

  #calculating the norm of first 10 parameters
  norm_of_parameters = norm(first_10_param)
  print('norm_of_parameters--->',norm_of_parameters)

#Calculating norm using function for histogram
correct_norm = calculate_L2_norm(u, B, mean_free_data, mean_free_correct_data)
print(correct_norm)

plt.hist(correct_norm, bins=15)
plt.show()





"""##Generate mean_free data from the incorrect video and find it's L2 norm"""

# incorrect_video = pd.read_excel('/content/incorrect_video_1.xlsx')
# incorrect_video = incorrect_video.dropna()
in_col_mean = incorrect_video_1.mean(axis=0)

mean_free_incorrect_data = incorrect_video_1 - in_col_mean
mean_free_incorrect_data.head()

"""### Calculating L2 norm of incorrect videos"""

#for loop to iterate over all the meanfree data and calculates its norm
# print(test_correct_meanfree_data.shape)
rows, columns = mean_free_incorrect_data.shape

for i in range(rows):
  sample = mean_free_incorrect_data.iloc[i]
  sample = sample.to_numpy()

  param = generate_parameters_from_sample(u, B, sample, mean_free_data)
  #param = param.reshape((558,1))
  #print(param)

  first_10_param = param[:10]
  # print('First 10 parameters are--->',first_10_param)

  #calculating the norm of first 10 parameters
  norm_of_parameters = norm(first_10_param)
  print('norm_of_parameters--->',norm_of_parameters)

#Calculating norm using function for histogram
incorrect_norm = calculate_L2_norm(u, B, mean_free_data, mean_free_incorrect_data)
# print(correct_norm)

plt.hist(incorrect_norm, bins=15)
plt.show()

"""### Plot of correct and incorrect videos together"""

bins=20
plt.hist(correct_norm, bins, alpha=1.0, label='Correct Video')
plt.hist(incorrect_norm, bins, alpha=0.5, label='Partially Correct Video')
plt.hist(incorrect_norm_2, bins, alpha=0.5, label='Incorrect video')
plt.legend(loc='upper right')
plt.show()

#for video 2
# incorrect_video_2 = pd.read_excel('/content/incorrect_video_2.xlsx')
# incorrect_video_2 = incorrect_video_2.dropna()
in_col_mean = incorrect_video_2.mean(axis=0)

mean_free_incorrect_data_2 = incorrect_video_2 - in_col_mean
mean_free_incorrect_data_2.head()

#for loop to iterate over all the meanfree data and calculates its norm
# print(test_correct_meanfree_data.shape)
rows, columns = mean_free_incorrect_data_2.shape

for i in range(rows):
  sample = mean_free_incorrect_data_2.iloc[i]
  sample = sample.to_numpy()

  param = generate_parameters_from_sample(u, B, sample, mean_free_data)
  #param = param.reshape((558,1))
  #print(param)

  first_10_param = param[:10]
  # print('First 10 parameters are--->',first_10_param)

  #calculating the norm of first 10 parameters
  norm_of_parameters = norm(first_10_param)
  print('norm_of_parameters--->',norm_of_parameters)

#Calculating norm using function for histogram
incorrect_norm_2 = calculate_L2_norm(u, B, mean_free_data, mean_free_incorrect_data_2)
# print(correct_norm)

plt.hist(incorrect_norm_2, bins=15)
plt.show()

"""### Finding norms of correct videos"""

correct_video_2 = pd.read_excel('/content/drive/MyDrive/AI_fitness_app/Prathik_frontal.xlsx')
correct_video_2 = correct_video_2.dropna()
col_mean_2 = correct_video_2.mean(axis=0)

mean_free_correct_data_2 = correct_video_2 - col_mean_2
mean_free_correct_data_2.head()

#for loop to iterate over all the meanfree data and calculates its norm
# print(test_correct_meanfree_data.shape)
rows, columns = mean_free_correct_data_2.shape

for i in range(rows):
  sample = mean_free_correct_data_2.iloc[i]
  sample = sample.to_numpy()

  param = generate_parameters_from_sample(u, B, sample, mean_free_data)
  #param = param.reshape((558,1))
  #print(param)

  first_10_param = param[:10]
  # print('First 10 parameters are--->',first_10_param)

  #calculating the norm of first 10 parameters
  norm_of_parameters = norm(first_10_param)
  print('norm_of_parameters--->',norm_of_parameters)

#Calculating norm using function for histogram
correct_norm_2 = calculate_L2_norm(u, B, mean_free_data, mean_free_correct_data_2)
# print(correct_norm)

plt.hist(correct_norm_2, bins=15)
plt.show()



"""## Function to calculate L2 norm ****"""

def calculate_L2_norm(u, B, mean_free_data, test_data):

  rows, columns = test_data.shape
  norm_of_parameters_list = []

  for i in range(rows):
    sample = test_data.iloc[i]
    sample = sample.to_numpy()

    param = generate_parameters_from_sample(u, B, sample, mean_free_data)
    #param = param.reshape((558,1))
    #print(param)

    first_10_param = param[:10]
    # print('First 10 parameters are--->',first_10_param)

    #calculating the norm of first 10 parameters
    norm_of_parameters = norm(first_10_param)
    # print('norm_of_parameters--->',norm_of_parameters)
    norm_of_parameters_list.append(norm_of_parameters)
  return norm_of_parameters_list

"""#ploting the histogram of L2 norm"""

# incorrect video 1
in_normalized_data_frame = pd.DataFrame(in_normalized_data_list)

#store the norm of parameters of incorrect video 1
norm_of_incorrect_video_1 = calculate_L2_norm(u, B, mean_free_data, in_normalized_data_frame)

plt.hist(norm_of_incorrect_video_1, bins=20)
plt.show()

# incorrect video 2
in_normalized_data_frame_1 = pd.DataFrame(in_normalized_data_list_1)

#store the norm of parameters of incorrect video 2
norm_of_incorrect_video_2 = calculate_L2_norm(u, B, mean_free_data, in_normalized_data_frame_1)

plt.hist(norm_of_incorrect_video_2, bins=20)
plt.show()







# incorrect video 2
in_normalized_data_frame_1 = pd.DataFrame(in_normalized_data_list_1)
calculate_L2_norm(u, B, mean_free_data, in_normalized_data_frame_1)

"""#Subtract mean from the incorrect data"""

#mean free data of incorrect frame
incorrect_mean, incorrect_mean_free_data = calculate_mean_and_mean_free_data(in_normalized_data_list)

#Store the norm of parameters of incorrect video 1
norm_incorrect_Video_1 = calculate_L2_norm(u, B, mean_free_data, incorrect_mean_free_data)

plt.hist(norm_incorrect_Video_1, bins=20)
plt.show()



#mean free data of incorrect frame
incorrect_mean_1, incorrect_mean_free_data_1 = calculate_mean_and_mean_free_data(in_normalized_data_list_1)

#Store the norm of parameters of incorrect video 1
norm_incorrect_Video_2 = calculate_L2_norm(u, B, mean_free_data, incorrect_mean_free_data_1)

plt.hist(norm_incorrect_Video_2, bins=20)
plt.show()



"""#Regenrating samples from parameters"""

#Generating parameters from random sample of incorrect video
sample = incorrect_video_1.iloc[0]

sample.shape

#ploting the sample on reference image
sample = sample.to_numpy()

#subtracting mean from the sample
sample = sample - mean

sample_numpy = sample.reshape(23, 2)

transformed_sample_vector = get_transformed_vector(sample_numpy)

#Function that plot cordinates of the transformed vector on the image
plot_cordinates_on_image(transformed_sample_vector)

#No use

#Subtracting mean from the transformed sample
mean_free_transformed_sample_vector = transformed_sample_vector - mean.reshape(23, 2)

#No use

# print(mean_free_transformed_sample_vector)

plot_cordinates_on_image(mean_free_transformed_sample_vector)

#Generating parameters from the sample
param_of_sample = generate_parameters_from_sample(u, B, transformed_sample_vector, mean_free_data)
# print(param_of_sample)

#Calculating the norm of first 10 parameters
first_10_param = param_of_sample[:10]
# print('First 10 parameters are--->',first_10_param)

#calculating the norm of first 10 parameters
norm_of_parameters = norm(first_10_param)

print(norm_of_parameters)

"""From parameters, generating sample"""

sample = calculate_sample(u, B, param_of_sample, mean_free_data)

#adding mean to the sample

resultant_vector = sample.flatten()
resultant_vector = resultant_vector.reshape(23, 2)

# print(resultant_vector)

#plot the sample
plot_cordinates_on_image(resultant_vector)

#Setting the values of parameters to zero after 10th
new_param = param_of_sample

new_param[10:] = 0

print(new_param)



#Normalizing the Data in the range [0,1]
norm_resultant_vector = (resultant_vector-np.min(resultant_vector))/(np.max(resultant_vector)-np.min(resultant_vector))

plot_cordinates_on_image(norm_resultant_vector)



"""Generating sample from correct video

#Test
"""

pip install mediapipe opencv-python

pip install openpyxl

from pathlib import Path
import os

import cv2
import numpy as np
import mediapipe as mp
import uuid
import os
import json
import csv
import copy

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_pose = mp.solutions.pose
from google.colab.patches import cv2_imshow

import openpyxl as ox

for subdir, dirs, files in os.walk("/content/drive/MyDrive/Fitness App/Gym"):
    counter = 0
    for file in files:
        #print os.path.join(subdir, file)
        filepath = subdir + os.sep + file
        #print(filepath)

        filename = "/content/Book2Final.xlsx"
        wb = ox.load_workbook(filename)
        #print(wb)
        for ws in wb.worksheets:
          #print(ws.title)
          ws = wb.worksheets[0]

        cap = cv2.VideoCapture(filepath)

        dictionary = {}
        lst_row = []
        reference_landmarks = []
        with mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5) as pose:
          while cap.isOpened():
            success, image = cap.read()
            counter = counter + 1
            if (counter):
              print(counter)


              if not success:
                print("Ignoring empty camera frame.")
                # If loading a video, use 'break' instead of 'continue'.
                break

              # To improve performance, optionally mark the image as not writeable to
              # pass by reference.
              image.flags.writeable = False
              image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
              results = pose.process(image)
              #print(results.pose_landmarks)
              #dictionary = dict(results.pose_landmarks)
              landmark_counter = 0
              for idx in results.pose_landmarks.landmark:
                #print(idx.x,idx.y,idx.z)
                landmark_counter = landmark_counter + 1
                #print(landmark_counter)
                #write counter to json file
                if(landmark_counter == 0 or landmark_counter > 10):
                  reference_landmarks.append(idx.x)
                  reference_landmarks.append(idx.y)
                  #reference_landmarks.append(idx.z)
                #write to excel file
              #print(reference_landmarks)
              for j in range(len(reference_landmarks)):
                ws.cell(row=counter+1, column=j+1).value = str(reference_landmarks[j])
                wb.save(filename)

                #clear the list
              reference_landmarks.clear()

import cv2
import numpy as np
import mediapipe as mp
import uuid
import os
import json
import csv
import copy

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_pose = mp.solutions.pose
from google.colab.patches import cv2_imshow

import openpyxl as ox

filename = "/content/Book2Final.xlsx"
wb = ox.load_workbook(filename)
print(wb)
for ws in wb.worksheets:
  print(ws.title)
  ws = wb.worksheets[0]


cap = cv2.VideoCapture('/content/incorrect_video.mp4')
counter = 0
dictionary = {}
lst_row = []
reference_landmarks = []
with mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as pose:
  while cap.isOpened():
    success, image = cap.read()
    counter = counter + 1
    if (counter):
      print(counter)


      if not success:
        print("Ignoring empty camera frame.")
        # If loading a video, use 'break' instead of 'continue'.
        break

      # To improve performance, optionally mark the image as not writeable to
      # pass by reference.
      image.flags.writeable = False
      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
      results = pose.process(image)
      #print(results.pose_landmarks)
      #dictionary = dict(results.pose_landmarks)
      landmark_counter = 0
      for idx in results.pose_landmarks.landmark:
        #print(idx.x,idx.y,idx.z)
        landmark_counter = landmark_counter + 1
        #print(landmark_counter)
        #write counter to json file
        if(landmark_counter == 0 or landmark_counter > 10):
          reference_landmarks.append(idx.x)
          reference_landmarks.append(idx.y)
          #reference_landmarks.append(idx.z)
        #write to excel file
      print(reference_landmarks)
      for j in range(len(reference_landmarks)):
        ws.cell(row=counter+1, column=j+1).value = str(reference_landmarks[j])
        wb.save(filename)

        #clear the list
      reference_landmarks.clear()
#print(len(reference_landmarks))

"""# new dataset imports"""

from sklearn.metrics import accuracy_score

correct_video_landmarks = pd.read_excel('/content/drive/MyDrive/correct_videos.xlsx')
incorrect_video_landmarks = pd.read_excel('/content/drive/MyDrive/incorrect_videos.xlsx')

correct_video_landmarks = correct_video_landmarks.sample(5195)

incorrect_video_landmarks = incorrect_video_landmarks.sample(5195)

#correct_video_landmarks_1 = correct_video_landmarks.sample(5195)

l2_norm_correct_video_landmarks = calculate_L2_norm(u, B, mean_free_data, correct_video_landmarks)

print(len(l2_norm_correct_video_landmarks))

l2_norm_incorrect_video_landmarks = calculate_L2_norm(u, B, mean_free_data, incorrect_video_landmarks)

print(len(l2_norm_incorrect_video_landmarks))

correct_video_landmarks.insert(46,"Labels",1)

incorrect_video_landmarks.insert(46,"Labels",0)

print(correct_video_landmarks.shape)
print(incorrect_video_landmarks.shape)

frames = [correct_video_landmarks[:5195], incorrect_video_landmarks]

video_landmarks = pd.concat(frames)

print(video_landmarks.shape)

maximum_value = max(l2_norm_correct_video_landmarks)

minimum_value = min(l2_norm_correct_video_landmarks)

#accuracy
print(int(np.round(maximum_value)))

accuracy = []
for i in range(int(np.round(minimum_value)), int(np.round(maximum_value)), 1):
  #print(i)
  predicted = []
  for j in l2_norm_correct_video_landmarks:
    if (i > j):
      predicted.append(1)
    else:
      predicted.append(0)
    #find accuracy for the ith norm value
  #print(len(predicted))
  #print(len(l2_norm_correct_video_landmarks))
  accuracy.append(accuracy_score(correct_video_landmarks["Labels"], predicted))
print(len(accuracy))
plt.plot(np.arange(int(np.round(minimum_value)), int(np.round(maximum_value))),accuracy)

maximum_value = max(l2_norm_incorrect_video_landmarks)
minimum_value = min(l2_norm_incorrect_video_landmarks)

accuracy = []
for i in range(int(np.round(minimum_value)), int(np.round(maximum_value)), 1):
  #print(i)
  predicted = []
  for j in l2_norm_incorrect_video_landmarks:
    if (i > j):
      predicted.append(1)
    else:
      predicted.append(0)
    #find accuracy for the ith norm value
  #print(len(predicted))
  #print(len(l2_norm_correct_video_landmarks))
  accuracy.append(accuracy_score(incorrect_video_landmarks["Labels"], predicted))
print(len(accuracy))
plt.plot(np.arange(int(np.round(minimum_value)), int(np.round(maximum_value))),accuracy)

print(len(l2_norm_correct_video_landmarks))
print(len(l2_norm_incorrect_video_landmarks))

print(type(l2_norm_incorrect_video_landmarks))
l2_norm_video_landmarks = l2_norm_incorrect_video_landmarks + l2_norm_correct_video_landmarks[:5195]

"""#Function to find the threshold"""

def find_threshold(list_of_parameters, dataframe_of_labels):
  minimum_value_1 = min(list_of_parameters)
  maximum_value_2 = max(list_of_parameters)

  accuracy = []
  for i in range(int(np.round(minimum_value_1)), int(np.round(maximum_value_2)), 1):
    #print(i)
    predicted = []
    for j in list_of_parameters:
      if (i > j):
        predicted.append(1)
      else:
        predicted.append(0)
      #find accuracy for the ith norm value
    #print(len(predicted))
    #print(len(l2_norm_correct_video_landmarks))
    accuracy.append(accuracy_score(dataframe_of_labels["Labels"], predicted))
  print(len(accuracy))
  plt.plot(np.arange(int(np.round(minimum_value_1)), int(np.round(maximum_value_2))),accuracy)



find_threshold(l2_norm_video_landmarks, video_landmarks)

"""#histogram of correct and incorrect values"""

print(len(l2_norm_correct_video_landmarks))
print(len(l2_norm_incorrect_video_landmarks))

l2_norm_correct_video_landmarks_shortened = l2_norm_correct_video_landmarks[:5195]

bins=5
plt.hist(l2_norm_correct_video_landmarks, bins, alpha=1.0, label='Correct Video')
#plt.hist(incorrect_norm, bins, alpha=0.5, label='Partially Correct Video')
plt.hist(l2_norm_incorrect_video_landmarks, bins, alpha=0.5, label='Incorrect video')
plt.legend(loc='upper right')
plt.show()

bins=10
plt.hist(l2_norm_correct_video_landmarks, bins, alpha=1.0, label='Correct Video')
#plt.hist(incorrect_norm, bins, alpha=0.5, label='Partially Correct Video')
plt.hist(l2_norm_incorrect_video_landmarks, bins, alpha=0.5, label='Incorrect video')
plt.legend(loc='upper right')
plt.show()

bins=20
plt.hist(l2_norm_correct_video_landmarks, bins, alpha=1.0, label='Correct Video')
#plt.hist(incorrect_norm, bins, alpha=0.5, label='Partially Correct Video')
plt.hist(l2_norm_incorrect_video_landmarks, bins, alpha=0.5, label='Incorrect video')
plt.legend(loc='upper right')
plt.show()

correct_video_landmarks = pd.read_excel('/content/drive/MyDrive/correct_videos.xlsx')
incorrect_video_landmarks = pd.read_excel('/content/drive/MyDrive/incorrect_videos.xlsx')

mean_correct_video, mfd_correct_video = calculate_mean_and_mean_free_data(correct_video_landmarks)

def rigid_allignment_on_all_frames(data):
  rows, _ = data.shape

  #store the data in the normalized data list
  normalized_data_list = []

  for i in range(rows):

    #Get every 20th frame
    if (i % 10 == 0):
      print('Frame number is {}'.format(i))

      single_row = data.iloc[i]
      single_row_numpy = single_row.to_numpy()
      single_row_numpy = single_row_numpy.reshape(23, 2)

      transformed_vector = get_transformed_vector(single_row_numpy)

      #Function that plot cordinates of the transformed vector on the image
      plot_cordinates_on_image(transformed_vector)

      normalized_data_list.append(transformed_vector.flatten())

  return normalized_data_list

correct_data_align = rigid_allignment_on_all_frames(correct_video_landmarks)

def return_mse_error(actual_landmarks, predicted_landmarks):

  #check the length of both the dataframes
  # if(actual_landmarks.shape == predicted_landmarks.shape):
  #   return -1

  #calculating rows and columns
  rows, columns = actual_landmarks.shape

  #loop for every (frame) row and calculate the mean squared error for each frame and store it in the list
  mse_list = []

  for i in range(int(rows)):
    mse = mean_squared_error(np.array(actual_landmarks.iloc[i]), np.array(predicted_landmarks.iloc[i]))
    mse_list.append(mse)
  return mse_list

from sklearn.metrics import mean_squared_error
#List that stores Mean Squared Error
mse_list = []

#Generate Parameters
rows, columns = mfd_correct_video.shape

for i in range(rows):
  sample = mfd_correct_video.iloc[i]
  sample = sample.to_numpy()

  param = generate_parameters_from_sample(u, B, sample, mean_free_data)
  #param = param.reshape((558,1))
  #print(param)

  #From Parameters to Samples
  reg_sample = calculate_sample(u, B, param, mean_free_data)

  #Adding Mean
  resultant_vector = reg_sample.flatten() + mean_correct_video
  resultant_vector = resultant_vector.reshape(23, 2)

  # print('Actual Landmarks-->',(correct_data_align[i].shape))
  # print('Regenerated Landmarks-->',type(resultant_vector.shape))

  mse = mean_squared_error(correct_video_landmarks[i], resultant_vector.flatten())
  # print('MSE--->',mse)
  mse_list.append(mse)